<!doctype html>
<html lang="ko"><head>
<meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>15ì°¨ì‹œ ë¦¬í¬íŠ¸ v4 (3ê°œ ì½”ë“œ ì°¨ì´ ê°•ì¡°)</title>
<style>
:root{
  --bg0:#070A12; --bg1:#0B1020; --card:#10192E; --line:#22304f;
  --text:#EAF0FF; --muted:#B7C3E6; --accent:#7AA2FF;
  --good:#37D67A; --warn:#FFB020; --purple:#B592FF; --cyan:#35D0FF;
  --shadow:0 10px 30px rgba(0,0,0,.35);
}
*{box-sizing:border-box}
body{margin:0;color:var(--text);
  font-family:system-ui,-apple-system,Segoe UI,Roboto,Apple SD Gothic Neo,Noto Sans KR,Arial,sans-serif;
  background:radial-gradient(1200px 600px at 15% -10%, rgba(122,162,255,.16), transparent 55%),
             radial-gradient(900px 500px at 90% 5%, rgba(53,208,255,.10), transparent 55%),
             linear-gradient(180deg,var(--bg0),var(--bg1));
}
.container{max-width:1160px;margin:0 auto;padding:22px 16px 60px;}
header{padding:18px;border:1px solid var(--line);border-radius:18px;background:rgba(16,25,46,.85);box-shadow:var(--shadow);}
h1{margin:0 0 8px;font-size:26px;letter-spacing:-.2px}
.meta{margin:0;color:var(--muted);font-size:14px;line-height:1.6}
.grid{display:grid;grid-template-columns: 300px 1fr;gap:16px;margin-top:16px;}
@media(max-width:980px){.grid{grid-template-columns:1fr}.toc{position:relative;top:auto}}
.toc{position:sticky;top:16px;padding:14px;border:1px solid var(--line);border-radius:18px;background:rgba(16,25,46,.70);box-shadow:var(--shadow);}
.toc h2{margin:0 0 10px;font-size:16px;color:#dbe6ff}
.toc a{display:block;padding:8px 10px;border-radius:12px;color:var(--text);text-decoration:none;border:1px solid transparent}
.toc a:hover{background:rgba(122,162,255,.10);border-color:rgba(122,162,255,.20)}
.card{padding:18px;border:1px solid var(--line);border-radius:18px;background:rgba(16,25,46,.70);box-shadow:var(--shadow);margin-bottom:16px;}
.card h2{margin:0 0 10px;font-size:20px}
.card h3{margin:16px 0 8px;font-size:16px;color:#dbe6ff}
.small{color:var(--muted);font-size:13px;line-height:1.65}
p{margin:8px 0;line-height:1.75}
hr.sep{border:0;border-top:1px dashed rgba(122,162,255,.25);margin:14px 0}
.callout{display:flex;gap:12px;align-items:flex-start;padding:12px 14px;border-radius:16px;border:1px solid var(--line);background:rgba(7,11,21,.65);margin:10px 0;}
.icon{width:34px;height:34px;border-radius:12px;display:grid;place-items:center;font-weight:800;}
.icon.cyan{background:rgba(53,208,255,.14);border:1px solid rgba(53,208,255,.30);color:#bdefff}
.icon.purple{background:rgba(181,146,255,.14);border:1px solid rgba(181,146,255,.30);color:#eadcff}
.icon.good{background:rgba(55,214,122,.16);border:1px solid rgba(55,214,122,.35);color:#bdf7d3}
.icon.warn{background:rgba(255,176,32,.14);border:1px solid rgba(255,176,32,.35);color:#ffe0a8}
pre.code{margin:10px 0 0;padding:14px 14px;border-radius:16px;overflow:auto;
  background:linear-gradient(180deg,#060913,#070b15);border:1px solid #1e2a47;color:#e8eefc;font-size:13px;line-height:1.55;}
code{font-family:ui-monospace,SFMono-Regular,Menlo,Consolas,monospace}
.tbl{width:100%;border-collapse:separate;border-spacing:0;overflow:hidden;border-radius:16px;border:1px solid var(--line);margin-top:10px}
.tbl th,.tbl td{border-top:1px solid var(--line);border-right:1px solid var(--line);padding:10px;vertical-align:top}
.tbl th{background:rgba(122,162,255,.10);text-align:left}
.tbl tr:first-child th{border-top:0}
.tbl td:last-child,.tbl th:last-child{border-right:0}
.badges{display:flex;gap:8px;flex-wrap:wrap;margin-top:10px}
.badge{display:inline-flex;align-items:center;gap:8px;padding:6px 10px;border-radius:999px;font-size:12px;border:1px solid rgba(122,162,255,.28);background:rgba(122,162,255,.14);color:#dbe6ff}
.dot{width:8px;height:8px;border-radius:50%}
.dot.cyan{background:var(--cyan)} .dot.purple{background:var(--purple)} .dot.good{background:var(--good)} .dot.warn{background:var(--warn)}
.split2{display:grid;grid-template-columns:1fr 1fr;gap:12px}
@media(max-width:980px){.split2{grid-template-columns:1fr}}
.panel{padding:12px;border-radius:16px;border:1px solid rgba(122,162,255,.22);background:rgba(7,11,21,.55)}
.keybox{display:grid;grid-template-columns:1fr 1fr 1fr;gap:12px;margin-top:10px}
@media(max-width:980px){.keybox{grid-template-columns:1fr}}
.kcard{padding:12px;border-radius:16px;border:1px solid rgba(122,162,255,.22);background:rgba(7,11,21,.55)}
.kcard h4{margin:0 0 6px;font-size:14px}
footer{margin-top:10px;color:var(--muted);font-size:12px;text-align:center}
.muted{color:var(--muted)}
</style>
</head>
<body>
<div class="container">
<header>
  <h1>15ì°¨ì‹œ ë¦¬í¬íŠ¸ v4 <span style="color:var(--accent)">3ê°œ ì½”ë“œ ì°¨ì´ ê°•ì¡°</span></h1>
  <p class="meta">ì‘ì„±ì¼: 2026-01-30 Â· ëª©í‘œ: â€œì™œ 3ê°œê°€ ë‹¤ë¥¸ì§€â€ê°€ ì²« í˜ì´ì§€ë¶€í„° ë³´ì´ê²Œ ë§Œë“¤ê¸°(ë°ì´í„°/ì¦ê°•/ëª¨ë¸/í•™ìŠµì „ëµ ì¤‘ì‹¬)</p>
  <div class="badges">
    <span class="badge"><span class="dot good"></span>ì°¨ì´ ë¹„êµí‘œ</span>
    <span class="badge"><span class="dot warn"></span>ì¦ê°• ì°¨ì´</span>
    <span class="badge"><span class="dot cyan"></span>ëª¨ë¸ êµì²´</span>
    <span class="badge"><span class="dot purple"></span>ìŠ¤ì¼€ì¤„ëŸ¬/ì‹¤ë¬´ê¸°ë²•</span>
  </div>
</header>

<div class="grid">
  <nav class="toc">
    <h2>ëª©ì°¨</h2>
    <a href='#diff'>3ê°œ ì½”ë“œ ì°¨ì´ í•œëˆˆì—</a><a href='#01-custom-dl-imagefolder-vgg19-bn'>01) Custom DL + ImageFolder ì „ì´í•™ìŠµ(VGG19_BN)</a><a href='#02-cifar-10-resnet18'>02) CIFAR-10 ResNet18 íŒŒì¸íŠœë‹</a><a href='#03-cifar-10-vgg19-bn'>03) CIFAR-10 VGG19_BN íŒŒì¸íŠœë‹(ì‹¤ë¬´í˜•)</a>
    <hr class="sep"/>
    <p class="small muted">ì½ê¸° ì¶”ì²œ: <b>ë¹„êµí‘œ â†’ (03 ì‹¤ë¬´í˜•) â†’ (02 ResNet) â†’ (01 ImageFolder)</b></p>
  </nav>

  <main>
    
<section class="card" id="diff">
  <h2>3ê°œ ì½”ë“œê°€ â€œë‹¤ë¥´ê²Œ ë³´ì´ê²Œâ€ ë§Œë“œëŠ” í•µì‹¬ ë¹„êµí‘œ</h2>
  <div class="callout"><div class="icon good">âœ…</div><div>
    <p class="small"><b>ê²°ë¡ ë¶€í„°</b>: 3ê°œëŠ” â€œì „ë¶€ ë”¥ëŸ¬ë‹ í•™ìŠµâ€ì´ë¼ ê²‰ íë¦„ì€ ë¹„ìŠ·í•˜ì§€ë§Œ, <b>ë°ì´í„°/ì¦ê°•/ëª¨ë¸/í•™ìŠµ ìµœì í™”</b>ê°€ ì„œë¡œ ë‹¬ë¼ìš”.</p>
    <p class="small">ê·¸ë˜ì„œ ì•„ë˜ í‘œì²˜ëŸ¼ â€œì°¨ì´ë¥¼ ë¨¼ì €â€ ì¡ê³  ë“¤ì–´ê°€ì•¼ ë¦¬í¬íŠ¸ê°€ ì„¤ë“ë ¥ ìˆì–´ì§‘ë‹ˆë‹¤.</p>
  </div></div>
  <table class='tbl'><tr><th>ì½”ë“œ</th><th>ë°ì´í„°</th><th>ìŠ¤í¬ë˜ì¹˜ ì í•©?</th><th>ëª¨ë¸</th><th>í•™ìŠµ/ìµœì í™”</th><th>ì´ ë…¸íŠ¸ë¶ë§Œì˜ í¬ì¸íŠ¸</th></tr><tr><td>01 Custom DL</td><td>ImageFolder (ì‚¬ìš©ì í´ë” ê²½ë¡œ)</td><td>ë¶€ì í•©(ëŒ€ê°œ ë°ì´í„°ê°€ ì œí•œì ) â†’ ì „ì´í•™ìŠµ ê¶Œì¥</td><td>VGG19_BN(pretrained) + classifier[6]ë¥¼ 2í´ë˜ìŠ¤ë¡œ êµì²´</td><td>SGD, (ë…¸íŠ¸ë¶ì—ì„ ) Freeze ì˜ˆì‹œ ì¡´ì¬ + ì¦ê°• ì ìš©/ë¯¸ì ìš© ë¹„êµ</td><td>â€˜ë‚´ ë°ì´í„°â€™ë¥¼ ImageFolderë¡œ ë‹¤ë£¨ëŠ” ë°©ë²• + ì „ì´í•™ìŠµ ê¸°ë³¸í˜•</td></tr><tr><td>02 ResNet18</td><td>CIFAR-10 (50k/10k, 32Ã—32, 10í´ë˜ìŠ¤)</td><td>ê°€ëŠ¥í•˜ì§€ë§Œ ëª©í‘œê°€ ì „ì´í•™ìŠµ/íŒŒì¸íŠœë‹ íë¦„ â†’ pretrained ì‚¬ìš©</td><td>ResNet18(weights=IMAGENET1K_V1) + fcë¥¼ 10í´ë˜ìŠ¤ë¡œ êµì²´</td><td>SGD + weight_decay + CosineAnnealingLR(ìŠ¤ì¼€ì¤„ë§)</td><td>â€˜ê°€ë³ê³  ë¹ ë¥¸â€™ ResNet18 + ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ë¡œ ì•ˆì • ìˆ˜ë ´</td></tr><tr><td>03 VGG19 ì‹¤ë¬´í˜•</td><td>CIFAR-10 (32Ã—32) + (ë…¸íŠ¸ë¶ì—ì„œ) 128â†’112ë¡œ ë¦¬ì‚¬ì´ì¦ˆ/í¬ë¡­</td><td>ê°€ëŠ¥í•˜ì§€ë§Œ VGGëŠ” íŒŒë¼ë¯¸í„°ê°€ ì»¤ì„œ ì „ì´í•™ìŠµì´ ë” í•©ë¦¬ì </td><td>VGG19_BN(weights=IMAGENET1K_V1) + classifier[6]ë¥¼ 10í´ë˜ìŠ¤ë¡œ êµì²´</td><td>Label Smoothing + SGD(nesterov) + OneCycleLR + Mixed Precision(GradScaler)</td><td>â€˜ì‹¤ë¬´ ìµœì í™” íŒ¨í‚¤ì§€â€™(ê°•í•œ ì¦ê°•/ìŠ¤ì¼€ì¤„/AMP) ëª¨ìŒ</td></tr></table>
</section>

<section class="card" id="01-custom-dl-imagefolder-vgg19-bn">
  <h2>01) Custom DL + ImageFolder ì „ì´í•™ìŠµ(VGG19_BN)</h2>

  <div class="callout"><div class="icon cyan">ğŸ§©</div><div>
    <p class="small"><b>ì´ ë…¸íŠ¸ë¶ì˜ â€œì°¨ë³„ì  3ê°œâ€</b> (ì—¬ê¸°ë§Œ ë´ë„ ë‹¤ë¥¸ ì½”ë“œì²˜ëŸ¼ ëŠê»´ì§€ê²Œ)</p>
  </div></div>
  <div class="keybox"><div class='kcard'><h4>ë°ì´í„°</h4><p class='small'>ImageFolderë¡œ &#x27;ë‚´ í´ë” ë°ì´í„°&#x27;ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹</p></div><div class='kcard'><h4>ì‹¤í—˜ í¬ì¸íŠ¸</h4><p class='small'>ì¦ê°• ì ìš©(train_transform) vs ë¯¸ì ìš©(test_transform) ë¹„êµ</p></div><div class='kcard'><h4>í•™ìŠµ ì „ëµ</h4><p class='small'>VGG19_BN pretrained + classifierë¥¼ 2í´ë˜ìŠ¤ë¡œ êµì²´ (ì „ì´í•™ìŠµ ê¸°ë³¸í˜•)</p></div></div>

  <hr class="sep"/>
  <h3>1) ë°ì´í„°ê°€ ë­ê³ , ìŠ¤í¬ë˜ì¹˜ê°€ ì í•©í•œê°€?</h3>
  <div class="split2">
    <div class="panel">
      <p class="small"><b>ë°ì´í„° ì½”ë“œ(ì›ë¬¸)</b></p>
      <pre class='code'><code># ë°ì´í„°ì…‹ ì •ì˜
# í›ˆë ¨
# í›ˆë ¨1(ë°ì´í„° ì¦ê°• ì ìš©)
train_data1 = datasets.ImageFolder(train_dir, transform=train_transform)
# í›ˆë ¨2(ë¯¸ì ìš©)
train_data2 = datasets.ImageFolder(train_dir, transform=test_transform)

# ê²€ì¦
test_data = datasets.ImageFolder(test_dir, transform=test_transform)</code></pre>
    </div>
    <div class="panel">
      <p class="small"><b>íŒë‹¨(ì¤‘í•™ìƒ ë²„ì „)</b></p>
      <ul class="small">
        <li><b>ë°ì´í„°ê°€ ì‘ê±°ë‚˜ íŠ¹ìˆ˜í•˜ë©´</b>: ì²˜ìŒë¶€í„° í•™ìŠµ(ìŠ¤í¬ë˜ì¹˜)ì€ ê³¼ì í•© ìœ„í—˜ì´ ì»¤ìš” â†’ ì „ì´í•™ìŠµì´ ì•ˆì „</li>
        <li><b>ë°ì´í„°ê°€ ì¶©ë¶„íˆ í¬ë©´</b>: ìŠ¤í¬ë˜ì¹˜ë„ ê°€ëŠ¥í•˜ì§€ë§Œ, ëª©ì ì´ â€œì „ì´í•™ìŠµ ë¹„êµâ€ë©´ pretrainedê°€ ë” ì í•©</li>
        <li><b>ì´ ë…¸íŠ¸ë¶ì€</b>: ìœ„ ì½”ë“œ/ì„¤ì • ë•Œë¬¸ì— ì „ì´í•™ìŠµ/íŒŒì¸íŠœë‹ ë°©ì‹ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ìˆì–´ìš”</li>
      </ul>
    </div>
  </div>

  <hr class="sep"/>
  <h3>2) ì „ì²˜ë¦¬/ì¦ê°•ì´ ì–´ë–»ê²Œ ë‹¤ë¥´ì§€?</h3>
  <div class="callout"><div class="icon warn">ğŸ§ª</div><div>
    <p class="small"><b>í¬ì¸íŠ¸</b>: 01ì€ â€œì¦ê°• ì ìš©/ë¯¸ì ìš© ë¹„êµâ€, 03ì€ â€œì‹¤ë¬´í˜• ê°•í•œ ì¦ê°•â€, 02ëŠ” ê¸°ë³¸ ì¦ê°• + ì•ˆì • ìˆ˜ë ´ ì¤‘ì‹¬ì…ë‹ˆë‹¤.</p>
  </div></div>
  <pre class='code'><code># ê²€ì¦: í¬ê¸° ì¡°ì ˆ, ì¤‘ì•™ë¶€ë¶„ í¬ë¡­, í…ì„œ ë³€í™˜, ì „ê·œí™”

test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))
])

# í›ˆë ¨: ë°ì´í„° ì¦ê°• ê¸°ë²• ì¶”ê°€
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    # í…ì„œ ë³€í™˜ì€ ë°˜ë“œì‹œ ì •ê·œí™” ì´ì „ì—
    # í…ì„œë¡œ ë³€í™˜ë˜ë©´ value=0(ê²€ì€ìƒ‰)~1 ì‚¬ì´ì—ì„œ ì‹¤í–‰ë¨
    transforms.ToTensor(),
    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33),
                             ratio=(0.3, 3.3), value=0, inplace=False),
    # p: í•™ë¥  / scale: ì‚­ì œ ì˜ì—­ ë¹„ìœ¨ / ratio: ê°€ë¡œ/ì„¸ë¡œ ë¹„ìœ¨
    # value: ì§€ì›Œì§„ ì˜ì—­ ì±„ìš¸ ê°’ / inplace: ì›ë³¸ ìˆ˜ì • ì—¬ë¶€
    # ì •ê·œí™” ë§ˆì§€ë§‰ì—
    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))
])</code></pre>

  <hr class="sep"/>
  <h3>3) ëª¨ë¸ì€ ë­ê³ , ì–´ë””ë¥¼ ë°”ê¿¨ì§€?</h3>
  <pre class='code'><code>from torchvision import models

net = models.vgg19_bn(pretrained=True)

# ë‚œìˆ˜ê³ ì •
torch_seed()

# fc ì¶œë ¥ len(classes) = 2
in_features = net.classifier[6].in_features
net.classifier[6] = nn.Linear(in_features, 2)</code></pre>

  <hr class="sep"/>
  <h3>4) í•™ìŠµ ì „ëµ(Optimizer/Scheduler)ì´ ì™œ ë‹¤ë¥´ì§€?</h3>
  <p class='small muted'>ë…¸íŠ¸ë¶ì—ì„œ í•´ë‹¹ íŒ¨í„´ì˜ ì½”ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤(ë‹¤ë¥¸ ì…€ì— í©ì–´ì ¸ ìˆì„ ìˆ˜ ìˆì–´ìš”).</p>

  <details style="margin-top:12px;border:1px solid rgba(122,162,255,.22);border-radius:16px;background:rgba(7,11,21,.45);padding:10px 12px">
    <summary style="cursor:pointer;color:#dbe6ff;font-weight:700">ë…¸íŠ¸ë¶ì— Freeze ì½”ë“œê°€ ìˆëŠ”ì§€ í™•ì¸(ìˆìœ¼ë©´ ì›ë¬¸ í‘œì‹œ)</summary>
    <pre class='code'><code>from torchvision import models

net = models.vgg19_bn(pretrained=True)
# [ë³€ê²½ì  1] ëª¨ë“  íŒŒë¼ë¯¸í„°ì˜ ê²½ì‚¬ ê³„ì‚°ì„ ë™ê²°(ê°€ì¤‘ì¹˜ ë™ê²°)
for params in net.parameters():
    params.requires_grad = False

# ë‚œìˆ˜ê³ ì •
torch.seed()

# ìµœì¢… ë…¸ë“œ ì¶œë ¥ 2 (ì´ì§„ ë¶„ë¥˜) ë³€ê²½
# ì´ ë…¸ë“œì— ëŒ€í•´ì„œë§Œ ê²½ì‚¬ ê³„ì‚° ìˆ˜í–‰
in_features = net.classifier[6].in_features
net.classifier[6] = nn.Linear(in_features, 2)
# AdaptiveAvgPool2d í•¨ìˆ˜ ì œê±°
net.avgpool = nn.Identity()

net = net.to(device)
# í•™ìŠµë¥ 
lr = 0.001

# ì†ì‹¤í•¨ìˆ˜
criterion = nn.CrossEntropyLoss()

# ìµœì í™” í•¨ìˆ˜ ì •ì˜
# [ë³€ê²½ì  2] ìµœì í™”í•¨ìˆ˜ì— ìˆ˜ì •í•  íŒŒë¼ë¯¸í„°ë¥¼ ìµœì¢… ë…¸ë“œë¡œ ì œí•œ
optimizer = optim.SGD(net.classifier[6].parameters(), lr=lr, momentum=0.9)

history = np.zeros((0,5))</code></pre>
    <p class="small muted">Freeze ì½”ë“œê°€ ì—†ëŠ” ë…¸íŠ¸ë¶ì€ ê¸°ë³¸ì ìœ¼ë¡œ <b>ëª¨ë“  íŒŒë¼ë¯¸í„° í•™ìŠµ</b>(Full)ë¡œ ì“°ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ëŒ€ì‹  ìŠ¤ì¼€ì¤„ëŸ¬/ì •ê·œí™”ë¡œ ì•ˆì •ì„±ì„ ì¡ìŠµë‹ˆë‹¤.</p>
  </details>

</section>

<section class="card" id="02-cifar-10-resnet18">
  <h2>02) CIFAR-10 ResNet18 íŒŒì¸íŠœë‹</h2>

  <div class="callout"><div class="icon cyan">ğŸ§©</div><div>
    <p class="small"><b>ì´ ë…¸íŠ¸ë¶ì˜ â€œì°¨ë³„ì  3ê°œâ€</b> (ì—¬ê¸°ë§Œ ë´ë„ ë‹¤ë¥¸ ì½”ë“œì²˜ëŸ¼ ëŠê»´ì§€ê²Œ)</p>
  </div></div>
  <div class="keybox"><div class='kcard'><h4>ëª¨ë¸</h4><p class='small'>ResNet18ì€ ê°€ë³ê³  ë¹ ë¥´ë©° 32Ã—32ì—ì„œë„ ì˜ ë™ì‘</p></div><div class='kcard'><h4>í•™ìŠµë¥  ì „ëµ</h4><p class='small'>CosineAnnealingLRë¡œ lrì„ ë¶€ë“œëŸ½ê²Œ ê°ì†Œ</p></div><div class='kcard'><h4>ì •ê·œí™”</h4><p class='small'>weight_decayë¡œ ê³¼ì í•© ì–µì œ(L2 ì •ê·œí™”)</p></div></div>

  <hr class="sep"/>
  <h3>1) ë°ì´í„°ê°€ ë­ê³ , ìŠ¤í¬ë˜ì¹˜ê°€ ì í•©í•œê°€?</h3>
  <div class="split2">
    <div class="panel">
      <p class="small"><b>ë°ì´í„° ì½”ë“œ(ì›ë¬¸)</b></p>
      <pre class='code'><code># CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ
def load_data(batch_size=64):
    train_transform, val_transform = get_transforms()


    # í›ˆë ¨ ë°ì´í„°
    train_dataset = torchvision.datasets.CIFAR10(
        root=&#x27;./data&#x27;,
        train=True,
        download=True,
        transform=train_transform
    )


    # ê²€ì¦ ë°ì´í„°
    val_dataset = torchvision.datasets.CIFAR10(
        root=&#x27;./data&#x27;,
        train=False,
        download=True,
        transform=val_transform
    )


    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2,
        pin_memory=True  # GPU ì „ì†¡ ì†ë„ í–¥ìƒ
    )


    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )


    return train_loader, val_loader


# ë°ì´í„° ë¡œë“œ
train_loader, val_loader = load_data(batch_size=64)


# í´ë˜ìŠ¤ ì´ë¦„
class_names = [&#x27;airplane&#x27;, &#x27;automobile&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;deer&#x27;,
               &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;]


print(f&#x27;í›ˆë ¨ ë°ì´í„°: {len(train_loader.dataset)}ê°œ&#x27;)
print(f&#x27;ê²€ì¦ ë°ì´í„°: {len(val_loader.dataset)}ê°œ&#x27;)
print(f&#x27;ë°°ì¹˜ í¬ê¸°: {train_loader.batch_size}&#x27;)</code></pre>
    </div>
    <div class="panel">
      <p class="small"><b>íŒë‹¨(ì¤‘í•™ìƒ ë²„ì „)</b></p>
      <ul class="small">
        <li><b>ë°ì´í„°ê°€ ì‘ê±°ë‚˜ íŠ¹ìˆ˜í•˜ë©´</b>: ì²˜ìŒë¶€í„° í•™ìŠµ(ìŠ¤í¬ë˜ì¹˜)ì€ ê³¼ì í•© ìœ„í—˜ì´ ì»¤ìš” â†’ ì „ì´í•™ìŠµì´ ì•ˆì „</li>
        <li><b>ë°ì´í„°ê°€ ì¶©ë¶„íˆ í¬ë©´</b>: ìŠ¤í¬ë˜ì¹˜ë„ ê°€ëŠ¥í•˜ì§€ë§Œ, ëª©ì ì´ â€œì „ì´í•™ìŠµ ë¹„êµâ€ë©´ pretrainedê°€ ë” ì í•©</li>
        <li><b>ì´ ë…¸íŠ¸ë¶ì€</b>: ìœ„ ì½”ë“œ/ì„¤ì • ë•Œë¬¸ì— ì „ì´í•™ìŠµ/íŒŒì¸íŠœë‹ ë°©ì‹ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ìˆì–´ìš”</li>
      </ul>
    </div>
  </div>

  <hr class="sep"/>
  <h3>2) ì „ì²˜ë¦¬/ì¦ê°•ì´ ì–´ë–»ê²Œ ë‹¤ë¥´ì§€?</h3>
  <div class="callout"><div class="icon warn">ğŸ§ª</div><div>
    <p class="small"><b>í¬ì¸íŠ¸</b>: 01ì€ â€œì¦ê°• ì ìš©/ë¯¸ì ìš© ë¹„êµâ€, 03ì€ â€œì‹¤ë¬´í˜• ê°•í•œ ì¦ê°•â€, 02ëŠ” ê¸°ë³¸ ì¦ê°• + ì•ˆì • ìˆ˜ë ´ ì¤‘ì‹¬ì…ë‹ˆë‹¤.</p>
  </div></div>
  <pre class='code'><code># ë°ì´í„° ë³€í™˜ ì •ì˜
def get_transforms():
  # í›ˆë ¨ ë°ì´í„° ë³€í™˜(ë°ì´í„° ì¦ê°•)
  train_transform = transforms.Compose([
      transforms.Resize(128), # í¬ê¸° ê³ ì •
      transforms.RandomCrop(112),
      transforms.RandomHorizontalFlip(p=0.5), # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „
      transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # ìƒ‰ìƒë³€í™˜


      transforms.ToTensor(),
      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])


  ])
  # ê²€ì¦ ë°ì´í„° ë³€í™˜(ì¦ê°• ì—†ì–´ì•¼ í•¨)
  val_transform = transforms.Compose([
      transforms.Resize(112), # í¬ê¸° ê³ ì • (ê°€ë¡œ ì„¸ë¡œ ë¹„ìœ¨ ìœ ì§€) Resize((112,112))
      # transforms.CenterCrop(112) : ì¤‘ì•™ì— ìœ„ì¹˜ 112*112 ë¡œ ì˜ë¼ì„œ ë§Œë“¤ì–´ì¤˜ (ì •ë³´ì†ì‹¤ ê°€ëŠ¥)


      transforms.ToTensor(),
      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])


  ])


  return train_transform, val_transform</code></pre>

  <hr class="sep"/>
  <h3>3) ëª¨ë¸ì€ ë­ê³ , ì–´ë””ë¥¼ ë°”ê¿¨ì§€?</h3>
  <pre class='code'><code># ì›ë˜ resnet ì€ imagenet ì— ì‚¬ìš©ëœ ì‚¬ì „í•™ìŠµëœ ê°€ì¤‘ì¹˜ì„
# ì´ ëª¨ë¸ì€ 1000ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜í•˜ëŠ” ë¶„ë¥˜ê¸°
# ìš°ë¦¬ ëª¨ë¸ì— ë§ì¶¤ ì„œë¹„ìŠ¤ í•˜ê¸° ìœ„í•´ ë§ˆì§€ë§‰ fc layer (ë¶„ë¥˜ê¸° classfier) 10ê°œ í´ë˜ìŠ¤ë¡œ ë³€ê²½ ì‘ì—… í•„ìš”

def create_model(num_classes=10, pretrained=True):
    # ì‚¬ì „ í•™ìŠµëœ ResNet-18 ëª¨ë¸ ë¡œë“œ
    # pretrain=Trueë©´ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
    model = models.resnet18(weights=&#x27;IMAGENET1K_V1&#x27; if pretrained else None)

    # ë§ˆì§€ë§‰ fc(ë¶„ë¥˜ê¸°) ì…ë ¥ ì°¨ì› í™•ì¸
    num_features = model.fc.in_features
    # print(num_features)  # 512

    num_classes = 10

    # nn.Linear(in_features=num_features, out_features=num_classes, bias=True)
    model.fc = nn.Linear(num_features, num_classes)
    # print(model.fc)
    # Linear(in_features=512, out_features=10, bias=True)

    model = model.to(device)
    return model</code></pre>

  <hr class="sep"/>
  <h3>4) í•™ìŠµ ì „ëµ(Optimizer/Scheduler)ì´ ì™œ ë‹¤ë¥´ì§€?</h3>
  <pre class='code'><code># í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
from tqdm import tqdm
import time
import copy

# í•œê¸€ í°íŠ¸ ì„¤ì • (Colab)
plt.rcParams[&#x27;font.family&#x27;] = &#x27;DejaVu Sans&#x27;
plt.rcParams[&#x27;axes.unicode_minus&#x27;] = False

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)
print(f&#x27;ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}&#x27;)
if torch.cuda.is_available():
    print(f&#x27;GPU ì´ë¦„: {torch.cuda.get_device_name(0)}&#x27;)</code></pre>

  <details style="margin-top:12px;border:1px solid rgba(122,162,255,.22);border-radius:16px;background:rgba(7,11,21,.45);padding:10px 12px">
    <summary style="cursor:pointer;color:#dbe6ff;font-weight:700">ë…¸íŠ¸ë¶ì— Freeze ì½”ë“œê°€ ìˆëŠ”ì§€ í™•ì¸(ìˆìœ¼ë©´ ì›ë¬¸ í‘œì‹œ)</summary>
    <p class='small muted'>ë…¸íŠ¸ë¶ì—ì„œ í•´ë‹¹ íŒ¨í„´ì˜ ì½”ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤(ë‹¤ë¥¸ ì…€ì— í©ì–´ì ¸ ìˆì„ ìˆ˜ ìˆì–´ìš”).</p>
    <p class="small muted">Freeze ì½”ë“œê°€ ì—†ëŠ” ë…¸íŠ¸ë¶ì€ ê¸°ë³¸ì ìœ¼ë¡œ <b>ëª¨ë“  íŒŒë¼ë¯¸í„° í•™ìŠµ</b>(Full)ë¡œ ì“°ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ëŒ€ì‹  ìŠ¤ì¼€ì¤„ëŸ¬/ì •ê·œí™”ë¡œ ì•ˆì •ì„±ì„ ì¡ìŠµë‹ˆë‹¤.</p>
  </details>

</section>

<section class="card" id="03-cifar-10-vgg19-bn">
  <h2>03) CIFAR-10 VGG19_BN íŒŒì¸íŠœë‹(ì‹¤ë¬´í˜•)</h2>

  <div class="callout"><div class="icon cyan">ğŸ§©</div><div>
    <p class="small"><b>ì´ ë…¸íŠ¸ë¶ì˜ â€œì°¨ë³„ì  3ê°œâ€</b> (ì—¬ê¸°ë§Œ ë´ë„ ë‹¤ë¥¸ ì½”ë“œì²˜ëŸ¼ ëŠê»´ì§€ê²Œ)</p>
  </div></div>
  <div class="keybox"><div class='kcard'><h4>ì¦ê°•(ì‹¤ë¬´í˜•)</h4><p class='small'>Resize/RandomResizedCrop/ColorJitter/RandomErasing ë“± â€˜ê°•í•œ ì¦ê°•â€™</p></div><div class='kcard'><h4>í•™ìŠµë¥  ì „ëµ</h4><p class='small'>OneCycleLR + warm-up/annealing</p></div><div class='kcard'><h4>ì‹¤ë¬´ ìµœì í™”</h4><p class='small'>Label smoothing + Nesterov + Mixed Precision(GradScaler)</p></div></div>

  <hr class="sep"/>
  <h3>1) ë°ì´í„°ê°€ ë­ê³ , ìŠ¤í¬ë˜ì¹˜ê°€ ì í•©í•œê°€?</h3>
  <div class="split2">
    <div class="panel">
      <p class="small"><b>ë°ì´í„° ì½”ë“œ(ì›ë¬¸)</b></p>
      <pre class='code'><code># ê³ ê¸‰ ë°ì´í„° ì¦ê°•
def get_advanced_transforms():
    &quot;&quot;&quot;
    ê³ ê¸‰ ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸
    ì‹¤ë¬´ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²• ì ìš©
    &quot;&quot;&quot;
    # í›ˆë ¨ ë°ì´í„° ë³€í™˜
    train_transform = transforms.Compose([
        transforms.Resize(128), # img 128*128 resize
        transforms.RandomResizedCrop(112, scale=(0.8, 1.0)),
        # ëœë¤ í¬ë¡­, 112*112 80%-100% í¬ê¸°ë¡œ resize
        transforms.RandomHorizontalFlip(p=0.5),
        # 50% í™•ë¥ ë¡œ ì¢Œìš°ë°˜ì „
        transforms.RandomRotation(degrees=15),  # ëœë¤ íšŒì „(-15~+15ë„)
        transforms.ColorJitter(
            brightness=0.3,  # ë°ê¸° ë³€í™”(+-30%)
            contrast=0.3,    # ëŒ€ë¹„ ë³€í™”(+-30%)
            saturation=0.3,  # ì±„ë„ ë³€í™”(+-30%)
            hue=0.1          # ìƒ‰ì¡° ë³€í™”(+-10%)
        ),
        transforms.ToTensor(), # PIL &gt;&gt; [0,1] í…ì„œë¡œ ë³€í™˜
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
        transforms.RandomErasing(p=0.3, scale=(0.02, 0.15))
        # CutOut íš¨ê³¼, 30% í™•ë¥ ë¡œ 2-15% ì˜ì—­ ì§€ì›€
    ])

    # ê²€ì¦ ë°ì´í„° ë³€í™˜ (ì¦ê°• ì—†ìŒ)
    val_transform = transforms.Compose([
        transforms.Resize(112),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

    return train_transform, val_transform

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_data(batch_size=50, num_workers=4):
    &quot;&quot;&quot;
    CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ

    Args:
        batch_size: ë°°ì¹˜ í¬ê¸°
        num_workers: ë°ì´í„° ë¡œë”© ì›Œì»¤ ìˆ˜
    &quot;&quot;&quot;
    train_transform, val_transform = get_advanced_transforms()

    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = torchvision.datasets.CIFAR10(
        root=&#x27;./data&#x27;,
        train=True,
        download=True,
        transform=train_transform
    )

    val_dataset = torchvision.datasets.CIFAR10(
        root=&#x27;./data&#x27;,
        train=False,
        download=True,
        transform=val_transform
    )

    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,  # GPU ì „ì†¡ ì†ë„ í–¥ìƒ
        persistent_workers=True  # ì›Œì»¤ ì¬ì‚¬ìš©(ì†ë„ í–¥ìƒ)
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
        persistent_workers=True
    )

    return train_loader, val_loader, train_dataset, val_dataset

# ë°ì´í„° ë¡œë“œ
train_loader, val_loader, train_dataset, val_dataset = load_data(
    batch_size=50,
    num_workers=2
)

# í´ë˜ìŠ¤ ì´ë¦„
class_names = [&#x27;airplane&#x27;, &#x27;automobile&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;deer&#x27;,
               &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;]

print(&#x27;\në°ì´í„° ë¡œë“œ ì™„ë£Œ&#x27;)
print(&#x27;=&#x27; * 60)
print(f&#x27;í›ˆë ¨ ë°ì´í„°: {len(train_dataset):,}ê°œ&#x27;)
print(f&#x27;ê²€ì¦ ë°ì´í„°: {len(val_dataset):,}ê°œ&#x27;)
print(f&#x27;ë°°ì¹˜ í¬ê¸°: {train_loader.batch_size}&#x27;)
print(f&#x27;ë°°ì¹˜ ìˆ˜ (í›ˆë ¨): {len(train_loader)}&#x27;)
print(f&#x27;ë°°ì¹˜ ìˆ˜ (ê²€ì¦): {len(val_loader)}&#x27;)
print(f&#x27;í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}&#x27;)
print(&#x27;=&#x27; * 60)</code></pre>
    </div>
    <div class="panel">
      <p class="small"><b>íŒë‹¨(ì¤‘í•™ìƒ ë²„ì „)</b></p>
      <ul class="small">
        <li><b>ë°ì´í„°ê°€ ì‘ê±°ë‚˜ íŠ¹ìˆ˜í•˜ë©´</b>: ì²˜ìŒë¶€í„° í•™ìŠµ(ìŠ¤í¬ë˜ì¹˜)ì€ ê³¼ì í•© ìœ„í—˜ì´ ì»¤ìš” â†’ ì „ì´í•™ìŠµì´ ì•ˆì „</li>
        <li><b>ë°ì´í„°ê°€ ì¶©ë¶„íˆ í¬ë©´</b>: ìŠ¤í¬ë˜ì¹˜ë„ ê°€ëŠ¥í•˜ì§€ë§Œ, ëª©ì ì´ â€œì „ì´í•™ìŠµ ë¹„êµâ€ë©´ pretrainedê°€ ë” ì í•©</li>
        <li><b>ì´ ë…¸íŠ¸ë¶ì€</b>: ìœ„ ì½”ë“œ/ì„¤ì • ë•Œë¬¸ì— ì „ì´í•™ìŠµ/íŒŒì¸íŠœë‹ ë°©ì‹ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ìˆì–´ìš”</li>
      </ul>
    </div>
  </div>

  <hr class="sep"/>
  <h3>2) ì „ì²˜ë¦¬/ì¦ê°•ì´ ì–´ë–»ê²Œ ë‹¤ë¥´ì§€?</h3>
  <div class="callout"><div class="icon warn">ğŸ§ª</div><div>
    <p class="small"><b>í¬ì¸íŠ¸</b>: 01ì€ â€œì¦ê°• ì ìš©/ë¯¸ì ìš© ë¹„êµâ€, 03ì€ â€œì‹¤ë¬´í˜• ê°•í•œ ì¦ê°•â€, 02ëŠ” ê¸°ë³¸ ì¦ê°• + ì•ˆì • ìˆ˜ë ´ ì¤‘ì‹¬ì…ë‹ˆë‹¤.</p>
  </div></div>
  <pre class='code'><code># ê³ ê¸‰ ë°ì´í„° ì¦ê°•
def get_advanced_transforms():
    &quot;&quot;&quot;
    ê³ ê¸‰ ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸
    ì‹¤ë¬´ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²• ì ìš©
    &quot;&quot;&quot;
    # í›ˆë ¨ ë°ì´í„° ë³€í™˜
    train_transform = transforms.Compose([
        transforms.Resize(128), # img 128*128 resize
        transforms.RandomResizedCrop(112, scale=(0.8, 1.0)),
        # ëœë¤ í¬ë¡­, 112*112 80%-100% í¬ê¸°ë¡œ resize
        transforms.RandomHorizontalFlip(p=0.5),
        # 50% í™•ë¥ ë¡œ ì¢Œìš°ë°˜ì „
        transforms.RandomRotation(degrees=15),  # ëœë¤ íšŒì „(-15~+15ë„)
        transforms.ColorJitter(
            brightness=0.3,  # ë°ê¸° ë³€í™”(+-30%)
            contrast=0.3,    # ëŒ€ë¹„ ë³€í™”(+-30%)
            saturation=0.3,  # ì±„ë„ ë³€í™”(+-30%)
            hue=0.1          # ìƒ‰ì¡° ë³€í™”(+-10%)
        ),
        transforms.ToTensor(), # PIL &gt;&gt; [0,1] í…ì„œë¡œ ë³€í™˜
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
        transforms.RandomErasing(p=0.3, scale=(0.02, 0.15))
        # CutOut íš¨ê³¼, 30% í™•ë¥ ë¡œ 2-15% ì˜ì—­ ì§€ì›€
    ])

    # ê²€ì¦ ë°ì´í„° ë³€í™˜ (ì¦ê°• ì—†ìŒ)
    val_transform = transforms.Compose([
        transforms.Resize(112),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

    return train_transform, val_transform

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_data(batch_size=50, num_workers=4):
    &quot;&quot;&quot;
    CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ

    Args:
        batch_size: ë°°ì¹˜ í¬ê¸°
        num_workers: ë°ì´í„° ë¡œë”© ì›Œì»¤ ìˆ˜
    &quot;&quot;&quot;
    train_transform, val_transform = get_advanced_transforms()

    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = torchvision.datasets.CIFAR10(
        root=&#x27;./data&#x27;,
        train=True,
        download=True,
        transform=train_transform
    )

    val_dataset = torchvision.datasets.CIFAR10(
        root=&#x27;./data&#x27;,
        train=False,
        download=True,
        transform=val_transform
    )

    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,  # GPU ì „ì†¡ ì†ë„ í–¥ìƒ
        persistent_workers=True  # ì›Œì»¤ ì¬ì‚¬ìš©(ì†ë„ í–¥ìƒ)
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
        persistent_workers=True
    )

    return train_loader, val_loader, train_dataset, val_dataset

# ë°ì´í„° ë¡œë“œ
train_loader, val_loader, train_dataset, val_dataset = load_data(
    batch_size=50,
    num_workers=2
)

# í´ë˜ìŠ¤ ì´ë¦„
class_names = [&#x27;airplane&#x27;, &#x27;automobile&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;deer&#x27;,
               &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;]

print(&#x27;\në°ì´í„° ë¡œë“œ ì™„ë£Œ&#x27;)
print(&#x27;=&#x27; * 60)
print(f&#x27;í›ˆë ¨ ë°ì´í„°: {len(train_dataset):,}ê°œ&#x27;)
print(f&#x27;ê²€ì¦ ë°ì´í„°: {len(val_dataset):,}ê°œ&#x27;)
print(f&#x27;ë°°ì¹˜ í¬ê¸°: {train_loader.batch_size}&#x27;)
print(f&#x27;ë°°ì¹˜ ìˆ˜ (í›ˆë ¨): {len(train_loader)}&#x27;)
print(f&#x27;ë°°ì¹˜ ìˆ˜ (ê²€ì¦): {len(val_loader)}&#x27;)
print(f&#x27;í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}&#x27;)
print(&#x27;=&#x27; * 60)</code></pre>

  <hr class="sep"/>
  <h3>3) ëª¨ë¸ì€ ë­ê³ , ì–´ë””ë¥¼ ë°”ê¿¨ì§€?</h3>
  <pre class='code'><code># VGG-19-BN ëª¨ë¸ ìƒì„±
def create_vgg19_bn(num_classes=10, pretrained=True):
    &quot;&quot;&quot;
    VGG-19-BN ëª¨ë¸ ìƒì„± ë° ìˆ˜ì •

    Args:
        num_classes: ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜
        pretrained: ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€
    &quot;&quot;&quot;
    # ì‚¬ì „ í•™ìŠµëœ VGG-19-BN ë¶ˆëŸ¬ì˜¤ê¸°
    if pretrained:
        model = models.vgg19_bn(weights=&#x27;IMAGENET1K_V1&#x27;)
    else:
        model = models.vgg19_bn(weights=None)

    # classifier êµ¬ì¡° ì¶œë ¥
    print(&#x27;ì›ë³¸ Classifier êµ¬ì¡°:&#x27;)
    print(model.classifier)
    print(&#x27;\n&#x27; + &#x27;=&#x27; * 60)

    # ë§ˆì§€ë§‰ FC ë ˆì´ì–´ êµì²´
    num_features = model.classifier[6].in_features
    print(f&#x27;ì›ë³¸ FC ë ˆì´ì–´: Linear(in_features={num_features}, out_features=1000)&#x27;)

    # CIFAR-10ì˜ 10ê°œ í´ë˜ìŠ¤ì— ë§ê²Œ êµì²´
    model.classifier[6] = nn.Linear(num_features, num_classes)
    print(f&#x27;êµì²´ëœ FC ë ˆì´ì–´: Linear(in_features={num_features}, out_features={num_classes})&#x27;)
    print(&#x27;=&#x27; * 60)

    # ëª¨ë¸ì„ GPUë¡œ ì´ë™
    model = model.to(device)

    return model

# ëª¨ë¸ ìƒì„±
model = create_vgg19_bn(num_classes=10, pretrained=True)

# ëª¨ë¸ íŒŒë¼ë¯¸í„° í†µê³„
def count_parameters(model):
    &quot;&quot;&quot;ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°&quot;&quot;&quot;
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total, trainable

total_params, trainable_params = count_parameters(model)

print(&#x27;\nëª¨ë¸ íŒŒë¼ë¯¸í„° í†µê³„:&#x27;)
print(&#x27;=&#x27; * 60)
print(f&#x27;ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}&#x27;)
print(f&#x27;í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {trainable_params:,}&#x27;)
print(f&#x27;ëª¨ë¸ í¬ê¸°: {total_params * 4 / 1024 / 1024:.2f} MB (float32 ê¸°ì¤€)&#x27;)
print(&#x27;=&#x27; * 60)</code></pre>

  <hr class="sep"/>
  <h3>4) í•™ìŠµ ì „ëµ(Optimizer/Scheduler)ì´ ì™œ ë‹¤ë¥´ì§€?</h3>
  <pre class='code'><code># ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import OneCycleLR
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler  # Mixed Precision Training
from torch.utils.tensorboard import SummaryWriter

import torchvision
import torchvision.transforms as transforms
import torchvision.models as models

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
from tqdm import tqdm
import time
import os
from datetime import datetime

# Grad-CAM
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget

print(&#x27;ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!&#x27;)</code></pre>

  <details style="margin-top:12px;border:1px solid rgba(122,162,255,.22);border-radius:16px;background:rgba(7,11,21,.45);padding:10px 12px">
    <summary style="cursor:pointer;color:#dbe6ff;font-weight:700">ë…¸íŠ¸ë¶ì— Freeze ì½”ë“œê°€ ìˆëŠ”ì§€ í™•ì¸(ìˆìœ¼ë©´ ì›ë¬¸ í‘œì‹œ)</summary>
    <p class='small muted'>ë…¸íŠ¸ë¶ì—ì„œ í•´ë‹¹ íŒ¨í„´ì˜ ì½”ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤(ë‹¤ë¥¸ ì…€ì— í©ì–´ì ¸ ìˆì„ ìˆ˜ ìˆì–´ìš”).</p>
    <p class="small muted">Freeze ì½”ë“œê°€ ì—†ëŠ” ë…¸íŠ¸ë¶ì€ ê¸°ë³¸ì ìœ¼ë¡œ <b>ëª¨ë“  íŒŒë¼ë¯¸í„° í•™ìŠµ</b>(Full)ë¡œ ì“°ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ëŒ€ì‹  ìŠ¤ì¼€ì¤„ëŸ¬/ì •ê·œí™”ë¡œ ì•ˆì •ì„±ì„ ì¡ìŠµë‹ˆë‹¤.</p>
  </details>

</section>

    <footer>ë‹¨ì¼ HTML(ë‚´ì¥ CSS) Â· GitHub Pages ì—…ë¡œë“œ ê°€ëŠ¥</footer>
  </main>
</div>
</div>
</body></html>
