# AIì‘ìš©_5ì°¨ì‹œ_í•µì‹¬ì½”ë“œ.md
> ì£¼ì œ: CNN ê¸°ë°˜ ë¶„ë¥˜ + ì „ì´í•™ìŠµ(Transfer Learning) + ëŒ€í‘œ ì•„í‚¤í…ì²˜(LeNet/AlexNet/VGG/GoogLeNet)

---

## 0) ğŸ”¥ ê³µí†µ: ë°ì´í„° íŒŒì´í”„ë¼ì¸ (Custom Dataset â†’ DataLoader)
```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

train_tf = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
])

val_tf = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
])

train_ds = datasets.ImageFolder("data/train", transform=train_tf)
val_ds   = datasets.ImageFolder("data/val",   transform=val_tf)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)
val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2)

num_classes = len(train_ds.classes)
```

- **ì™œ í•µì‹¬?** 5ì°¨ì‹œ ëª©í‘œ(ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹/ì „ì´í•™ìŠµ)ëŠ” ê²°êµ­ â€œë°ì´í„°ë¥¼ í‘œì¤€ í˜•íƒœë¡œ ê³µê¸‰â€í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì—ì„œ ì‹œì‘.
- **ëŒ€í‘œ ê°œë…:** Resize/Normalizeë¡œ ì…ë ¥ ë¶„í¬ ì •ë ¬ â†’ í•™ìŠµ ì•ˆì •í™”.
- **ë‹¤ìŒ í™•ì¥:** Augmentation ê°•ë„ ì¡°ì ˆ, ë¶ˆê· í˜• ì²˜ë¦¬(WeightedSampler/ê°€ì¤‘ì¹˜ ì†ì‹¤).

---

## 1) ğŸ”¥ LeNet: CNN êµ¬ì¡° ì´í•´ì˜ ê¸°ì¤€ ëª¨ë¸
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class LeNet(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)      # (N,1,32,32) -> (N,6,28,28)
        self.pool  = nn.AvgPool2d(2, 2)                  # -> (N,6,14,14)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)     # -> (N,16,10,10)
        # pool -> (N,16,5,5)
        self.fc1 = nn.Linear(16*5*5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, num_classes)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)          # (N, 16*5*5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)                  # logits
        return x
```

- **ì™œ í•µì‹¬?** Convâ†’Poolâ†’FCë¡œ â€œíŠ¹ì§• ì¶”ì¶œâ†’ìš”ì•½â†’ë¶„ë¥˜â€ íë¦„ì„ ê°€ì¥ ë‹¨ìˆœí•˜ê²Œ ê³ ì •í•˜ëŠ” ê¸°ì¤€ì .
- **ëŒ€í‘œ ê°œë…:** í•©ì„±ê³±(íŠ¹ì§•) / í’€ë§(ìš”ì•½Â·ë¶ˆë³€ì„±) / FC(ê²°ì •).
- **ë‹¤ìŒ í™•ì¥:** ë” ê¹Šì€ ëª¨ë¸(VGG/ResNet) + BN/Dropout ì¶”ê°€.

---

## 2) ğŸ”¥ í•™ìŠµ ë£¨í”„: â€œCNN ë¶„ë¥˜ê°€ ì‹¤ì œë¡œ í•™ìŠµë˜ëŠ” ë°©ì‹â€
```python
import torch.optim as optim

device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

def run_one_epoch(model, loader, train: bool):
    model.train(train)
    total_loss, correct, total = 0.0, 0, 0

    for x, y in loader:
        x, y = x.to(device), y.to(device)

        if train:
            optimizer.zero_grad()

        logits = model(x)
        loss = criterion(logits, y)

        if train:
            loss.backward()
            optimizer.step()

        total_loss += loss.item() * x.size(0)
        pred = logits.argmax(dim=1)
        correct += (pred == y).sum().item()
        total += y.size(0)

    return total_loss / total, correct / total
```

- **ì™œ í•µì‹¬?** ëª¨ë¸ì´ ìˆì–´ë„ â€œloss/optimizer/train-eval ëª¨ë“œâ€ê°€ ì—†ìœ¼ë©´ í•™ìŠµì´ ì„±ë¦½í•˜ì§€ ì•ŠìŒ.
- **ëŒ€í‘œ ê°œë…:** logits â†’ CrossEntropyLoss(ë‚´ë¶€ softmax ê°œë…)ë¡œ í™•ë¥ ì  ë¶„ë¥˜ í•™ìŠµ.
- **ë‹¤ìŒ í™•ì¥:** scheduler, early stopping, best model ì €ì¥/ë³µì›.

---

## 3) ğŸ”¥ Transfer Learning(AlexNet): â€œì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ë‚´ ë°ì´í„°ì— ë§ì¶˜ë‹¤â€
### 3-1) ë¡œë“œ + (ì„ íƒ) Freeze + ë¶„ë¥˜ê¸° êµì²´
```python
import torchvision.models as models

model = models.alexnet(weights=models.AlexNet_Weights.DEFAULT)

# (ì„ íƒ) íŠ¹ì§•ì¶”ì¶œê¸°ë¡œë§Œ ì“°ê³  ì‹¶ìœ¼ë©´ freeze
for p in model.features.parameters():
    p.requires_grad = False

# ë¶„ë¥˜ê¸° êµì²´ (ë§ˆì§€ë§‰ Linearë§Œ ë‚´ í´ë˜ìŠ¤ ìˆ˜ë¡œ)
model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)
model = model.to(device)
```

### 3-2) í•™ìŠµí•  íŒŒë¼ë¯¸í„°ë§Œ ì˜µí‹°ë§ˆì´ì €ì— ë“±ë¡
```python
params_to_update = [p for p in model.parameters() if p.requires_grad]
optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)
criterion = nn.CrossEntropyLoss()
```

- **ì™œ í•µì‹¬?** 5ì°¨ì‹œì˜ ì‹¤ë¬´ ì¶•: ì ì€ ë°ì´í„°ë¡œ ë¹ ë¥´ê²Œ ì„±ëŠ¥ì„ ë‚´ëŠ” ê°€ì¥ í‘œì¤€ì ì¸ ë°©ë²•.
- **ëŒ€í‘œ ê°œë…:** backbone(ì¬ì‚¬ìš© íŠ¹ì§•) + head(êµì²´ í•™ìŠµ) ë¶„ë¦¬.
- **ë‹¤ìŒ í™•ì¥:** partial fine-tune(ì¼ë¶€ ë¸”ë¡ unfreeze), íŒŒë¼ë¯¸í„° ê·¸ë£¹ë³„ í•™ìŠµë¥ (í—¤ë“œâ†‘ ë°±ë³¸â†“).

---

## 4) ğŸ”¥ Pretrained VGG13 Inference: â€œí•™ìŠµì´ ì•„ë‹ˆë¼ ì‚¬ìš©(ì¶”ë¡ )â€
```python
from PIL import Image
import torch
import torchvision.models as models

weights = models.VGG13_Weights.DEFAULT
model = models.vgg13(weights=weights).to(device)
model.eval()

preprocess = weights.transforms()

img = Image.open("test.jpg").convert("RGB")
x = preprocess(img).unsqueeze(0).to(device)  # (1,3,224,224)

with torch.no_grad():
    logits = model(x)
    pred = logits.argmax(dim=1).item()
```

- **ì™œ í•µì‹¬?** â€œì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ë°”ë¡œ ë¶„ë¥˜í•œë‹¤â€ëŠ” ë¶„ë¥˜ ì•±/ë°ëª¨ì˜ í•µì‹¬ íë¦„.
- **ëŒ€í‘œ ê°œë…:** eval/no_grad + (weights.transformsë¡œ) ì „ì²˜ë¦¬ ì¼ê´€ì„± ìœ ì§€.
- **ë‹¤ìŒ í™•ì¥:** top-k, confidence(softmax), ë°°ì¹˜ ì¶”ë¡ , TorchScript/ONNX.

---

## 5) ğŸ”¥ GoogLeNet/Inception: â€œì„±ëŠ¥ vs íš¨ìœ¨ì„ êµ¬ì¡°ë¡œ í•´ê²°â€
```python
import torch
import torch.nn as nn

class InceptionModule(nn.Module):
    def __init__(self, in_ch, c1, c3r, c3, c5r, c5, pool_proj):
        super().__init__()
        self.b1 = nn.Sequential(
            nn.Conv2d(in_ch, c1, kernel_size=1),
            nn.ReLU(inplace=True)
        )
        self.b2 = nn.Sequential(
            nn.Conv2d(in_ch, c3r, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(c3r, c3, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )
        self.b3 = nn.Sequential(
            nn.Conv2d(in_ch, c5r, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(c5r, c5, kernel_size=5, padding=2),
            nn.ReLU(inplace=True)
        )
        self.b4 = nn.Sequential(
            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),
            nn.Conv2d(in_ch, pool_proj, kernel_size=1),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        y1 = self.b1(x)
        y2 = self.b2(x)
        y3 = self.b3(x)
        y4 = self.b4(x)
        return torch.cat([y1, y2, y3, y4], dim=1)
```

- **ì™œ í•µì‹¬?** Inceptionì˜ ìš”ì§€ëŠ” â€œë³‘ë ¬ í•„í„° + 1Ã—1 ì°¨ì›ì¶•ì†Œâ€ë¡œ íŒŒë¼ë¯¸í„°/ì—°ì‚°ëŸ‰ì„ ì¤„ì´ë©´ì„œ ì„±ëŠ¥ ìœ ì§€.
- **ëŒ€í‘œ ê°œë…:** ë³‘ë ¬ ë¶„ê¸°(ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§•) + 1Ã—1 conv(ì°¨ì› ì¶•ì†Œ).
- **ë‹¤ìŒ í™•ì¥:** ResNet(skip), MobileNet(depthwise separable)ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§.

---
